# Which LLM server to talk to (local, lab, DRAC tunnel, etc.)
LLM_BASE_URL=http://localhost:8000/v1

# If your server requires a key; if not, can be anything
LLM_API_KEY=local-dev

# Whatever name the server exposes for the model
LLM_MODEL=llama-3.3-70b

# Generation settings
LLM_TEMPERATURE=0
LLM_MAX_TOKENS=1500

# Optional: request timeout (seconds)
LLM_TIMEOUT=120